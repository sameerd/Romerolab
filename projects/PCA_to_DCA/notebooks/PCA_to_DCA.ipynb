{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_file = os.path.join(datadir, \"DHFR.aln\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape = (56165, 186) ,dtype=  |S1\n"
     ]
    }
   ],
   "source": [
    "# Read all the lines in the file into a 2D array of type S1\n",
    "with open(msa_file) as fh:\n",
    "    arr = np.array([[x for x in line.strip()] for line in fh], np.dtype(\"S1\"))\n",
    "\n",
    "print(\"shape =\", arr.shape, \",dtype= \", arr.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M is the number of sequences\n",
    "# L is the length\n",
    "M, L = arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'VRPLNCIVAVSQNMGIGKNGDLPWPPLRNEFKYFQRMTTTSSVEGKQNLVIMGRKTWFSIPEKNRPLKDRINIVLSRELKEPPRGAHFLAKSLDDALRLIEQPELASKVDMVWIVGGSSVYQEAMNQPGHLRLFVTRIMQEFESDTFFPEIDLGKYKLLPEYPGVLSEVQEEKGIKYKFEVYEKKD'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the first sequence\n",
    "arr[0, :].tostring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'----SIVVVMCKRFGIGRNGVLPWSPLQADMQRFRSITAG-------GGVIMGRTTFDSIPEEHRPLQGRLNVVLTTSADLMKNSNIIFVSSFDELDAIVGL----HDHLPWHVIGGVSVYQHFLEKSQVTSMYVTFVDGSLECDTFFPHQFLSHFEITRA---SALMSDTTSGMSYRFVDYTR--'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the second sequence\n",
    "arr[1, :].tostring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can order the amino acids any way we like\n",
    "# Here is a sorting based on some amino acid properties. \n",
    "# https://proteinstructures.com/Structure/Structure/amino-acids.html\n",
    "AMINO_ACIDS = np.array([aa for aa in \"RKDEQNHSTCYWAILMFVPG-\"], \"S1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the weights of each sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_bar = True\n",
    "try:\n",
    "    from IPython.display import clear_output\n",
    "except ImportError:\n",
    "     progress_bar = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from :  ../data/DHFR.weights.npy\n"
     ]
    }
   ],
   "source": [
    "hamming_cutoff = 0.2 # This is x in equation 27 in the 2013 Coco et al. paper\n",
    "\n",
    "weights_file = os.path.join(datadir, \"DHFR.weights.npy\")\n",
    "\n",
    "if os.path.isfile(weights_file):\n",
    "    weights = np.load(weights_file)\n",
    "    print(\"Loading weights from : \", weights_file)\n",
    "\n",
    "else:\n",
    "    weights = np.zeros(M)\n",
    "\n",
    "    for i in range(M):\n",
    "        weights[i] = 1. / (np.sum(np.sum(arr[i, :] != arr, axis=1) < hamming_cutoff * L))\n",
    "        if i % 100 == 0:\n",
    "            if progress_bar:\n",
    "                clear_output(wait=True)\n",
    "            print (\"Processing sequence\", i, \"of\", M)\n",
    "    np.save(weights_file, weights)\n",
    "    print(\"Finished computing sequence weights and saved to : \", weights_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15238\n"
     ]
    }
   ],
   "source": [
    "M_eff = sum(weights) # Equation 28 in 2013 Coco et al. paper\n",
    "print(int(round(M_eff)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 21\n",
    "pseudo_count = round(M_eff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Single and Double site marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading single site marginals from  ../data/DHFR.single.npy\n",
      "Loading double site marginals from  ../data/DHFR.double.npy\n"
     ]
    }
   ],
   "source": [
    "single_site_marginal_file = os.path.join(datadir, \"DHFR.single.npy\")\n",
    "double_site_marginal_file = os.path.join(datadir, \"DHFR.double.npy\")\n",
    "\n",
    "if os.path.isfile(double_site_marginal_file) and os.path.isfile(single_site_marginal_file):\n",
    "    f_i_a = np.load(single_site_marginal_file)\n",
    "    print(\"Loading single site marginals from \", single_site_marginal_file)\n",
    "\n",
    "    f_i_j_a_b = np.load(double_site_marginal_file)\n",
    "    print(\"Loading double site marginals from \", double_site_marginal_file)    \n",
    "    \n",
    "else:\n",
    "    # single site marginals. Eqn 29 in 2013 Coco et al. paper\n",
    "    f_i_a = np.zeros((L, q))\n",
    "    # double site marginals\n",
    "    f_i_j_a_b = np.zeros((L*q, L*q))\n",
    "\n",
    "    normalizer = 1. / (M_eff + pseudo_count)\n",
    "    additive_factor_single = pseudo_count / q\n",
    "    additive_factor_double = pseudo_count / (q*q)\n",
    "\n",
    "    # This is a dictionary where the index (i,a) points to a \n",
    "    # numpy array of integers which is 1 if amino acid a is in row i\n",
    "    # and 0 otherwise \n",
    "    ia = dict()\n",
    "    for i, a in itertools.product(range(L), range(q)):\n",
    "        ia[(i, a)] = (arr[:, i] == AMINO_ACIDS[a]).astype(np.int)\n",
    "\n",
    "    for i, a in itertools.product(range(L), range(q)):\n",
    "        delta_i_a = ia[(i,a)]\n",
    "        f_i_a[i, a] =  normalizer * (additive_factor_single +\n",
    "                        np.sum(weights * delta_i_a))\n",
    "        for j, b in itertools.product(range(L), range(q)):\n",
    "            f_i_j_a_b[i + q*a, j + q*b] = normalizer * (additive_factor_double +\n",
    "                        np.sum(weights * ia[(j,b)] * delta_i_a ))\n",
    "        if progress_bar:\n",
    "            clear_output(wait=True)\n",
    "        print(\"Finished processing i={}, a={}, AA={}\".format(i, a, AMINO_ACIDS[a].tostring().decode()))\n",
    "\n",
    "    del ia\n",
    "    np.save(single_site_marginal_file, f_i_a)\n",
    "    np.save(double_site_marginal_file, f_i_j_a_b)\n",
    "    print(\"Finished computing sigle and double site marginals and saved to cache files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
